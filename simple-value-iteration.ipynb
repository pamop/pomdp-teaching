{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple value iteration example\n",
    "tiger problem  \n",
    "3/20/2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(R,T,gamma,nStates,nActions,max_error):\n",
    "    V = np.zeros([nStates,1])\n",
    "    Q = np.zeros([nStates,nActions])\n",
    "    t = 0\n",
    "    error = V + max_error + 1 # arbitrary to start while loop\n",
    "    while not all(i < max_error for i in error):\n",
    "        t = t+1\n",
    "#         print(\"TIMESTEP\",t)\n",
    "        V = np.append(V,np.zeros([nStates,1]),axis=1)\n",
    "        for s in range(nStates): \n",
    "            for a in range(nActions):\n",
    "                Q[s,a] = R[s,a] + gamma*np.dot(T[a,s,:],V[:,t-1])\n",
    "#             print(\"Q:\",Q)\n",
    "            V[s,t] = np.amax(Q[s,:]) \n",
    "        error = np.abs(V[:,t] - V[:,t-1])\n",
    "#         print('V_t:',V[:,t])\n",
    "#         print('error:',error)\n",
    "    \n",
    "    # Greedily select policy from V\n",
    "    policy = np.argmax(Q,axis=1)\n",
    "    \n",
    "    return V, policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's do a cute example: imagine there are 4 states, 2 actions.\n",
    "# You're starting a business and have to decide whether to save or advertise at each step.\n",
    "# You can be in one of 4 states: poor and unknown, poor and famous, rich and unknown, and rich and famous. \n",
    "# example courtesy of: http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/mdps.pdf\n",
    "\n",
    "# actions = save, advertise\n",
    "nActions = 2\n",
    "actions = [\"save\", \"advertise\"]\n",
    "# states = pu, pf, ru, rf\n",
    "nStates = 4\n",
    "states = [\"poor and unknown\",\"poor and famous\",\"rich and unknown\",\"rich and famous\"]\n",
    "\n",
    "# gamma: discount factor\n",
    "gamma = 0.9\n",
    "# R: rewards in each of four states same for both actions\n",
    "R = np.array([[0,0],[0,0],[10,10],[10,10]]) \n",
    "# T: 4x4x2 matrix of probabilities of transitions between states for the two actions\n",
    "T = np.array([[[1,0,0,0],[0.5,0,0,0.5],[0.5,0,0.5,0],[0,0,0.5,0.5]],\n",
    "              [[0.5,0.5,0,0],[0,1,0,0],[0.5,0.5,0,0],[0,1,0,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPolicy(policy,states,actions):\n",
    "    for i in range(len(policy)):\n",
    "        print(\"In state \" + states[i] + \", take policy \" + actions[policy[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [1 0 0 0]\n",
      "In state poor and unknown, take policy advertise\n",
      "In state poor and famous, take policy save\n",
      "In state rich and unknown, take policy save\n",
      "In state rich and famous, take policy save\n"
     ]
    }
   ],
   "source": [
    "# Define max_error (epsilon) and perform value iteration\n",
    "max_error = 0.01\n",
    "V,policy = value_iteration(R,T,gamma,nStates,nActions,max_error)\n",
    "print(\"Policy:\",policy)\n",
    "\n",
    "printPolicy(policy,states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = save, advertise\n",
    "nActions = 2\n",
    "actions = [\"take notes\", \"close eyes\"]\n",
    "# states = pu, pf, ru, rf\n",
    "nStates = 3\n",
    "states = [\"alert\",\"sleeping\",\"enlightenment\"]\n",
    "\n",
    "# gamma: discount factor\n",
    "gamma = 0.9\n",
    "# R: rewards in each of four states same for both actions\n",
    "R = np.array([[1,1],[5,5],[100,100]]) \n",
    "# T: 4x4x2 matrix of probabilities of transitions between states for the two actions\n",
    "T = np.array([[[0.7,0.1,0.2],[0.8,0.2,0],[0,0,1]],\n",
    "              [[0.2,0.8,0],[0,1,0],[0,0,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [0 0 0]\n",
      "In state alert, take policy take notes\n",
      "In state sleeping, take policy take notes\n",
      "In state enlightenment, take policy take notes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   1.        ,  20.08      ,  48.7054    ,\n",
       "         82.369486  , 118.74380122, 156.01876197, 192.94674446,\n",
       "        228.69959758, 262.75218402, 294.7959182 , 324.67524222,\n",
       "        352.34113874, 377.81725235, 401.17532713, 422.51751538,\n",
       "        441.96374354, 459.6427903 , 475.68608056, 490.22345816,\n",
       "        503.38039286, 515.27621989, 526.02311658, 535.72559915,\n",
       "        544.48038096, 552.37647665, 559.49546855, 565.91187484,\n",
       "        571.69357672, 576.90227411, 581.59394888, 585.81932128,\n",
       "        589.62429021, 593.05035135, 596.13498986, 598.9120459 ,\n",
       "        601.41205275, 603.66254776, 605.68835734, 607.5118571 ,\n",
       "        609.15320882, 610.63057574, 611.96031797, 613.15716939,\n",
       "        614.23439779, 615.2039496 , 616.07658069, 616.86197433,\n",
       "        617.56884772, 618.20504799, 618.77763884, 619.2929785 ,\n",
       "        619.75679007, 620.17422486, 620.54991943, 620.88804698,\n",
       "        621.19236358, 621.46624986, 621.71274852, 621.93459806,\n",
       "        622.1342632 , 622.31396225, 622.47569169, 622.62124842,\n",
       "        622.75224965, 622.87015089, 622.97626209, 623.07176225,\n",
       "        623.15771244, 623.23506766, 623.30468738, 623.36734515,\n",
       "        623.42373716, 623.47448998, 623.52016753, 623.56127733,\n",
       "        623.59827615, 623.6315751 , 623.66154415, 623.6885163 ,\n",
       "        623.71279124, 623.73463868, 623.75430138, 623.77199781,\n",
       "        623.7879246 , 623.80225871, 623.81515941, 623.82677004,\n",
       "        623.83721961, 623.84662422],\n",
       "       [  0.        ,   5.        ,   9.5       ,  21.1676    ,\n",
       "         43.878056  ,  72.20408   , 103.49227128, 135.96211745,\n",
       "        168.39483715, 199.97478094, 230.17703306, 258.68492705,\n",
       "        285.32946127, 310.04492292, 332.83650782, 353.75680694,\n",
       "        372.88883632, 390.33388588, 406.20290847, 420.61050153,\n",
       "        433.67078015, 445.49462329, 456.18791051, 465.85046783,\n",
       "        474.5755156 , 482.4494671 , 489.55196727, 495.95609147,\n",
       "        501.72864635, 506.93053158, 511.61713304, 515.83872714,\n",
       "        519.6408822 , 523.06484775, 526.14792557, 528.9238193 ,\n",
       "        531.42296052, 533.67281087, 535.69814034, 537.52128255,\n",
       "        539.16236797, 540.63953658, 541.96913112, 543.16587254,\n",
       "        544.24301902, 545.21250983, 546.08509548, 546.87045529,\n",
       "        547.57730347, 548.21348498, 548.78606185, 549.3013911 ,\n",
       "        549.76519492, 550.18262394, 550.55831421, 550.89643855,\n",
       "        551.20075276, 551.47463727, 551.72113461, 551.94298316,\n",
       "        552.14264757, 552.32234607, 552.48407511, 552.62963154,\n",
       "        552.76063254, 552.87853361, 552.98464469, 553.08014475,\n",
       "        553.16609488, 553.24345004, 553.31306972, 553.37572746,\n",
       "        553.43211945, 553.48287225, 553.52854979, 553.56965958,\n",
       "        553.6066584 , 553.63995734, 553.66992639, 553.69689854,\n",
       "        553.72117347, 553.74302092, 553.76268362, 553.78038005,\n",
       "        553.79630683, 553.81064094, 553.82354164, 553.83515227,\n",
       "        553.84560184, 553.85500645],\n",
       "       [  0.        , 100.        , 190.        , 271.        ,\n",
       "        343.9       , 409.51      , 468.559     , 521.7031    ,\n",
       "        569.53279   , 612.579511  , 651.3215599 , 686.18940391,\n",
       "        717.57046352, 745.81341717, 771.23207545, 794.10886791,\n",
       "        814.69798111, 833.228183  , 849.9053647 , 864.91482823,\n",
       "        878.42334541, 890.58101087, 901.52290978, 911.3706188 ,\n",
       "        920.23355692, 928.21020123, 935.38918111, 941.850263  ,\n",
       "        947.6652367 , 952.89871303, 957.60884172, 961.84795755,\n",
       "        965.6631618 , 969.09684562, 972.18716106, 974.96844495,\n",
       "        977.47160046, 979.72444041, 981.75199637, 983.57679673,\n",
       "        985.21911706, 986.69720535, 988.02748482, 989.22473634,\n",
       "        990.3022627 , 991.27203643, 992.14483279, 992.93034951,\n",
       "        993.63731456, 994.2735831 , 994.84622479, 995.36160231,\n",
       "        995.82544208, 996.24289787, 996.61860809, 996.95674728,\n",
       "        997.26107255, 997.5349653 , 997.78146877, 998.00332189,\n",
       "        998.2029897 , 998.38269073, 998.54442166, 998.68997949,\n",
       "        998.82098154, 998.93888339, 999.04499505, 999.14049554,\n",
       "        999.22644599, 999.30380139, 999.37342125, 999.43607913,\n",
       "        999.49247121, 999.54322409, 999.58890168, 999.63001151,\n",
       "        999.66701036, 999.70030933, 999.73027839, 999.75725055,\n",
       "        999.7815255 , 999.80337295, 999.82303565, 999.84073209,\n",
       "        999.85665888, 999.87099299, 999.88389369, 999.89550432,\n",
       "        999.90595389, 999.9153585 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define max_error (epsilon) and perform value iteration\n",
    "max_error = 0.01\n",
    "V,policy = value_iteration(R,T,gamma,nStates,nActions,max_error)\n",
    "print(\"Policy:\",policy)\n",
    "\n",
    "printPolicy(policy,states,actions)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [2 1]\n",
      "In state tiger-left, take policy open-right\n",
      "In state tiger-right, take policy open-left\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 10.        , 19.        , 27.1       , 34.39      ,\n",
       "        40.951     , 46.8559    , 52.17031   , 56.953279  , 61.2579511 ,\n",
       "        65.13215599, 68.61894039, 71.75704635, 74.58134172, 77.12320755,\n",
       "        79.41088679, 81.46979811, 83.3228183 , 84.99053647, 86.49148282,\n",
       "        87.84233454, 89.05810109, 90.15229098, 91.13706188, 92.02335569,\n",
       "        92.82102012, 93.53891811, 94.1850263 , 94.76652367, 95.2898713 ,\n",
       "        95.76088417, 96.18479576, 96.56631618, 96.90968456, 97.21871611,\n",
       "        97.4968445 , 97.74716005, 97.97244404, 98.17519964, 98.35767967,\n",
       "        98.52191171, 98.66972054, 98.80274848, 98.92247363, 99.03022627,\n",
       "        99.12720364, 99.21448328, 99.29303495, 99.36373146, 99.42735831,\n",
       "        99.48462248, 99.53616023, 99.58254421, 99.62428979, 99.66186081,\n",
       "        99.69567473, 99.72610726, 99.75349653, 99.77814688, 99.80033219,\n",
       "        99.82029897, 99.83826907, 99.85444217, 99.86899795, 99.88209815,\n",
       "        99.89388834, 99.9044995 , 99.91404955],\n",
       "       [ 0.        , 10.        , 19.        , 27.1       , 34.39      ,\n",
       "        40.951     , 46.8559    , 52.17031   , 56.953279  , 61.2579511 ,\n",
       "        65.13215599, 68.61894039, 71.75704635, 74.58134172, 77.12320755,\n",
       "        79.41088679, 81.46979811, 83.3228183 , 84.99053647, 86.49148282,\n",
       "        87.84233454, 89.05810109, 90.15229098, 91.13706188, 92.02335569,\n",
       "        92.82102012, 93.53891811, 94.1850263 , 94.76652367, 95.2898713 ,\n",
       "        95.76088417, 96.18479576, 96.56631618, 96.90968456, 97.21871611,\n",
       "        97.4968445 , 97.74716005, 97.97244404, 98.17519964, 98.35767967,\n",
       "        98.52191171, 98.66972054, 98.80274848, 98.92247363, 99.03022627,\n",
       "        99.12720364, 99.21448328, 99.29303495, 99.36373146, 99.42735831,\n",
       "        99.48462248, 99.53616023, 99.58254421, 99.62428979, 99.66186081,\n",
       "        99.69567473, 99.72610726, 99.75349653, 99.77814688, 99.80033219,\n",
       "        99.82029897, 99.83826907, 99.85444217, 99.86899795, 99.88209815,\n",
       "        99.89388834, 99.9044995 , 99.91404955]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do observable tiger problem\n",
    "\n",
    "# actions = listen, open-left, open-right\n",
    "nActions = 3\n",
    "actions = [\"listen\", \"open-left\", \"open-right\"]\n",
    "# states = pu, pf, ru, rf\n",
    "nStates = 2\n",
    "states = [\"tiger-left\",\"tiger-right\"]\n",
    "\n",
    "# gamma: discount factor\n",
    "gamma = 0.9\n",
    "# R: rewards \n",
    "R = np.array([[0,-100,10],[0,10,-100]]) \n",
    "# T: 2x2x3 matrix of probabilities of transitions between states for the three actions\n",
    "T = np.array([[[1,0],[0,1]],\n",
    "              [[0.5,0.5],[0.5,0.5]],\n",
    "              [[0.5,0.5],[0.5,0.5]]])\n",
    "\n",
    "# Define max_error (epsilon) and perform value iteration\n",
    "max_error = 0.01\n",
    "V,policy = value_iteration(R,T,gamma,nStates,nActions,max_error)\n",
    "print(\"Policy:\",policy)\n",
    "\n",
    "printPolicy(policy,states,actions)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
