{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running POMDPy examples in Jupyter notebook\n",
    "Pam Osborn Popp  \n",
    "pamop@nyu.edu  \n",
    "Feb 2018  \n",
    "\n",
    "### *pam's to-do:*\n",
    "- *Adjust valit method to use defaults when optional args are not supplied, and provide informative error messages when required args are not supplied*\n",
    "\n",
    "### PURPOSE:\n",
    "\n",
    "To give comprehensive instructions on how to set up and run the POMDPy examples in this Jupyter Notebook.\n",
    "\n",
    "### SET UP:\n",
    "###### Setting up an environment with all the proper packages to run this notebook\n",
    "\n",
    "This notebook must be run in a Python environment equipped with:\n",
    "- numpy >= 1.11\n",
    "- matplotlib >= 1.4.3\n",
    "- scipy >= 0.15.1\n",
    "- future >= 0.16\n",
    "- tensorflow >= 0.12\n",
    "\n",
    "The POMDPy library at https://github.com/pemami4911/POMDPy requires the above packages (access the link for more detail on dependencies and examples). Within the environment, the POMDPy library itself must also be installed.\n",
    "\n",
    "###### A comprehensive list of commands\n",
    "After downloading python 3 via the Anaconda distribution, the following commands are sufficient:\n",
    "\n",
    "```\n",
    "conda create -n tensorflow python=3.5 # To create the new environment\n",
    "source activate tensorflow # To enter the new environment\n",
    "easy_install -U pip # To update pip to enable use of pip3\n",
    "export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.1-py3-none-any.whl # To download tensorflow binary\n",
    "pip3 install --ignore-installed --upgrade $TF_BINARY_URL # To install tensorflow in the environment\n",
    "pip install --upgrade future # To install most recent version of future\n",
    "conda install scipy # To install scipy (can also use pip)\n",
    "conda install matplotlib # To install matplotlib\n",
    "conda install jupyter # To install jupyter\n",
    "pip install git+https://github.com/pemami4911/POMDPy.git # To install POMDPy repo\n",
    "jupyter notebook # To open jupyter notebook and run this file and others in this repository\n",
    "```\n",
    "\n",
    "To exit the tensorflow environment:\n",
    "```\n",
    "source deactivate\n",
    "```\n",
    "\n",
    "Emami, P., Hamlet, A. J., & Crane, C. D. POMDPy: An Extensible Framework for Implementing Partially-Observable Markov Decision Processes in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying your tensorflow install\n",
    "\n",
    "A good thing to do before getting ahead of one's self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "# Below is a cute test to verify tensorflow is installed and working properly.\n",
    "\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello).decode())\n",
    "\n",
    "# NOTE: you can also run this test in the command line to verify your tensorflow install - \n",
    "# within the tensorflow environment, after you have pip installed the tensorflow binary,\n",
    "# enter the command \"python\" to begin running python and then enter the above lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the \"Tiger\" POMDPy example\n",
    "\n",
    "POMDPy recommends running the following on the command line (in your environment) to run this example:\n",
    "\n",
    "```\n",
    "python vi.py --env Tiger --solver LinearAlphaNet --use_tf --n_epochs 5000 --max_steps 50 --test 5 --learning_rate 0.05 --learning_rate_decay 0.996 --learning_rate_minimum 0.00025 --learning_rate_decay_step 50 --beta 0.001 --epsilon_start 0.2 --epsilon_minimum 0.02 --epsilon_decay 0.99 --epsilon_decay_step 75 --seed 12157 --save\n",
    "```\n",
    "\n",
    "However, below we will run the example within this very notebook by slightly adjusting the vi.py function, as well as changing a few particular arguments (parameters) to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiger example\n",
    "from __future__ import print_function\n",
    "from libraries.pomdpy.pomdpy import Agent\n",
    "from libraries.pomdpy.pomdpy.solvers import ValueIteration\n",
    "from libraries.pomdpy.pomdpy.log import init_logger\n",
    "from libraries.pomdpy.examples.tiger import TigerModel\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value iteration function (adapted from libraries/pomdpy/vi.py which is suited for command line use)\n",
    "def valit(**args):\n",
    "# *** POP TODO ***\n",
    "# REQUIRED INPUTS:\n",
    "#     env=\"Tiger\" \n",
    "#     solver=\"LinearAlphaNet\" \n",
    "# Defaults:\n",
    "#     seed=1993\n",
    "#     use_tf=True\n",
    "#     discount=0.95\n",
    "#     n_epochs=1000\n",
    "#     max_steps=10\n",
    "#     save=False\n",
    "#     learning_rate=0.05, \n",
    "#     learning_rate_minimum=0.0025 # POP NOTE: in vi.py this is 0.0025 but in example it is 0.00025\n",
    "#     learning_rate_decay=0.996\n",
    "#     learning_rate_decay_step=50\n",
    "#     beta=0.001\n",
    "#     test=10\n",
    "#     epsilon_start=0.2 # POP NOTE: in vi.py this is 0.02 but I imagine must intend to be 0.2 as in example\n",
    "#     epsilon_minimum=0.05 # POP NOTE: in example this is 0.02\n",
    "#     epsilon_decay=0.96 # POP NOTE: in example this is 0.99\n",
    "#     epsilon_decay_step=75\n",
    "#     planning_horizon=5\n",
    "    \n",
    "    init_logger()\n",
    "\n",
    "    np.random.seed(int(args['seed']))\n",
    "\n",
    "    if args['solver'] == 'VI-Baseline':\n",
    "        from experiments.scripts import approximate_vi_eval\n",
    "\n",
    "        env = TigerModel(args)\n",
    "        solver = ValueIteration\n",
    "        agent = Agent(env, solver)\n",
    "        approximate_vi_eval.eval_baseline(args['n_epochs'], agent, args['planning_horizon'])\n",
    "\n",
    "    else:\n",
    "        if args['solver'] == 'ValueIteration':\n",
    "            solver = ValueIteration\n",
    "        elif args['use_tf'] and args['solver'] == 'LinearAlphaNet':\n",
    "            from pomdpy.solvers.linear_alpha_net import LinearAlphaNet\n",
    "            solver = LinearAlphaNet\n",
    "        else:\n",
    "            raise ValueError('solver not supported')\n",
    "\n",
    "        if args['env'] == 'Tiger':\n",
    "            env = TigerModel(args)\n",
    "            agent = Agent(env, solver)\n",
    "            agent.discounted_return()\n",
    "        else:\n",
    "            print('Unknown env {}'.format(args['env']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beta': 0.001,\n",
      " 'discount': 0.95,\n",
      " 'env': 'Tiger',\n",
      " 'epsilon_decay': 0.96,\n",
      " 'epsilon_decay_step': 75,\n",
      " 'epsilon_minimum': 0.05,\n",
      " 'epsilon_start': 0.2,\n",
      " 'learning_rate': 0.05,\n",
      " 'learning_rate_decay': 0.996,\n",
      " 'learning_rate_decay_step': 50,\n",
      " 'learning_rate_minimum': 0.0025,\n",
      " 'max_steps': 10,\n",
      " 'n_epochs': 1000,\n",
      " 'planning_horizon': 5,\n",
      " 'save': False,\n",
      " 'seed': 1993,\n",
      " 'solver': 'LinearAlphaNet',\n",
      " 'test': 10,\n",
      " 'use_tf': True}\n",
      " [*] Loading checkpoints...\n",
      " [!] Load FAILED: /Users/pamop/anaconda3/envs/tensorflow/lib/python3.5/site-packages/pomdpy/pomdp/../../experiments/checkpoints\n",
      "evaluating agent at epoch 0...\n",
      "evaluating agent at epoch 10...\n",
      "evaluating agent at epoch 20...\n",
      "evaluating agent at epoch 30...\n",
      "evaluating agent at epoch 40...\n",
      "evaluating agent at epoch 50...\n",
      "evaluating agent at epoch 60...\n",
      "evaluating agent at epoch 70...\n",
      "evaluating agent at epoch 80...\n",
      "evaluating agent at epoch 90...\n",
      "evaluating agent at epoch 100...\n",
      "evaluating agent at epoch 110...\n",
      "evaluating agent at epoch 120...\n",
      "evaluating agent at epoch 130...\n",
      "evaluating agent at epoch 140...\n",
      "evaluating agent at epoch 150...\n",
      "evaluating agent at epoch 160...\n",
      "evaluating agent at epoch 170...\n",
      "evaluating agent at epoch 180...\n",
      "evaluating agent at epoch 190...\n",
      "evaluating agent at epoch 200...\n",
      "evaluating agent at epoch 210...\n",
      "evaluating agent at epoch 220...\n",
      "evaluating agent at epoch 230...\n",
      "evaluating agent at epoch 240...\n",
      "evaluating agent at epoch 250...\n",
      "evaluating agent at epoch 260...\n",
      "evaluating agent at epoch 270...\n",
      "evaluating agent at epoch 280...\n",
      "evaluating agent at epoch 290...\n",
      "evaluating agent at epoch 300...\n",
      "evaluating agent at epoch 310...\n",
      "evaluating agent at epoch 320...\n",
      "evaluating agent at epoch 330...\n",
      "evaluating agent at epoch 340...\n",
      "evaluating agent at epoch 350...\n",
      "evaluating agent at epoch 360...\n",
      "evaluating agent at epoch 370...\n",
      "evaluating agent at epoch 380...\n",
      "evaluating agent at epoch 390...\n",
      "evaluating agent at epoch 400...\n",
      "evaluating agent at epoch 410...\n",
      "evaluating agent at epoch 420...\n",
      "evaluating agent at epoch 430...\n",
      "evaluating agent at epoch 440...\n",
      "evaluating agent at epoch 450...\n",
      "evaluating agent at epoch 460...\n",
      "evaluating agent at epoch 470...\n",
      "evaluating agent at epoch 480...\n",
      "evaluating agent at epoch 490...\n",
      "evaluating agent at epoch 500...\n",
      "evaluating agent at epoch 510...\n",
      "evaluating agent at epoch 520...\n",
      "evaluating agent at epoch 530...\n",
      "evaluating agent at epoch 540...\n",
      "evaluating agent at epoch 550...\n",
      "evaluating agent at epoch 560...\n",
      "evaluating agent at epoch 570...\n",
      "evaluating agent at epoch 580...\n",
      "evaluating agent at epoch 590...\n",
      "evaluating agent at epoch 600...\n",
      "evaluating agent at epoch 610...\n",
      "evaluating agent at epoch 620...\n",
      "evaluating agent at epoch 630...\n",
      "evaluating agent at epoch 640...\n",
      "evaluating agent at epoch 650...\n",
      "evaluating agent at epoch 660...\n",
      "evaluating agent at epoch 670...\n",
      "evaluating agent at epoch 680...\n",
      "evaluating agent at epoch 690...\n",
      "evaluating agent at epoch 700...\n",
      "evaluating agent at epoch 710...\n",
      "evaluating agent at epoch 720...\n",
      "evaluating agent at epoch 730...\n",
      "evaluating agent at epoch 740...\n",
      "evaluating agent at epoch 750...\n",
      "evaluating agent at epoch 760...\n",
      "evaluating agent at epoch 770...\n",
      "evaluating agent at epoch 780...\n",
      "evaluating agent at epoch 790...\n",
      "evaluating agent at epoch 800...\n",
      "evaluating agent at epoch 810...\n",
      "evaluating agent at epoch 820...\n",
      "evaluating agent at epoch 830...\n",
      "evaluating agent at epoch 840...\n",
      "evaluating agent at epoch 850...\n",
      "evaluating agent at epoch 860...\n",
      "evaluating agent at epoch 870...\n",
      "evaluating agent at epoch 880...\n",
      "evaluating agent at epoch 890...\n",
      "evaluating agent at epoch 900...\n",
      "evaluating agent at epoch 910...\n",
      "evaluating agent at epoch 920...\n",
      "evaluating agent at epoch 930...\n",
      "evaluating agent at epoch 940...\n",
      "evaluating agent at epoch 950...\n",
      "evaluating agent at epoch 960...\n",
      "evaluating agent at epoch 970...\n",
      "evaluating agent at epoch 980...\n",
      "evaluating agent at epoch 990...\n",
      "evaluating agent at epoch 1000...\n",
      "\n",
      "\n",
      "agent - epochs: 1000\n",
      "agent - ave undiscounted return/step: 5.380143932204556 +- 0.6482848034182911\n",
      "agent - ave discounted return/step: 5.063940211901471 +- 0.6157559052877136\n",
      "agent - ave time/epoch: 0.002204019244354551\n"
     ]
    }
   ],
   "source": [
    "valit(env=\"Tiger\", solver=\"LinearAlphaNet\", seed=1993, use_tf=True, discount=0.95, n_epochs=1000, max_steps=10, save=False, learning_rate=0.05, learning_rate_minimum=0.0025, learning_rate_decay=0.996, learning_rate_decay_step=50,beta=0.001, test=10, epsilon_start=0.2, epsilon_minimum=0.05, epsilon_decay=0.96, epsilon_decay_step=75, planning_horizon=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
