{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamagotchi POMCP\n",
    "pam o.p. 2018  \n",
    "Pomagotchi (Partially observable tamagotchi)  \n",
    "And POMCP solution method (MCTS in PO framework)  \n",
    "version 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime # for limiting calculation to wall clock time\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tamagotchi class adapted from https://github.com/bitterfly/tamagotchi/blob/master/tamagotchi/core/tamagotchi.py\n",
    "\n",
    "class Tamagotchi:\n",
    "    def __init__(self):\n",
    "        self.stats = {\"food\": 100, \"happiness\": 100, \"hygiene\": 100,\n",
    "                 \"health\": 100, \"energy\": 100}\n",
    "        self.is_sleeping = False\n",
    "        self.is_dead = False\n",
    "        self.is_playing = False\n",
    "        self.is_sick = False\n",
    "        self.number_of_poo = 0\n",
    "        self.money = 0\n",
    "        self.time = 0\n",
    "        self.in_store = False\n",
    "\n",
    "    #Makes sure the statistic isn't below 0 or above 100\n",
    "    def constrain(self, value):\n",
    "        value = min(100, value)\n",
    "        value = max(0, value)\n",
    "        return value\n",
    "\n",
    "    #Constrains all the stats\n",
    "    def constrain_stats(self):\n",
    "        for statistic, value in self.stats.items():\n",
    "            self.stats[statistic] = self.constrain(value)\n",
    "\n",
    "    #Takes a dictionary with statistics and adds each value\n",
    "    #to the tamagotchi statistics\n",
    "    def apply(self, item):\n",
    "#         for statistic, value in self.stats.items():\n",
    "#             self.stats[statistic] += item[statistic]\n",
    "        self.stats[item['stats']] += item['effect']\n",
    "        self.constrain_stats()\n",
    "\n",
    "#     #Takes a statistic and decreases it to zero in \"full hours\" time\n",
    "    def decrease_to_minimum(self, statistic, full_hours, time_given):\n",
    "        self.stats[statistic] -= 2 * np.ceil( (time_given * 10) / (full_hours * 36) ) \n",
    "#     def decrease_to_minimum(self, statistic, full_hours, time_given):\n",
    "#         self.stats[statistic] -= int(full_hours/2)\n",
    "\n",
    "#     #Takes a statistic and increases it to max in \"full hours\" time\n",
    "    def increase_to_maximum(self, statistic, full_hours, time_given):\n",
    "        self.stats[statistic] += 2 * np.ceil( (time_given * 10) / (full_hours * 36) ) \n",
    "#     def increase_to_maximum(self, statistic, full_hours, time_given):\n",
    "#         self.stats[statistic] += int(full_hours)\n",
    "\n",
    "    #Generates random sickness and poo\n",
    "    def random_event(self):\n",
    "        if (not self.is_playing and not self.is_sleeping):\n",
    "            random_number = randint(0, 600)\n",
    "            if random_number == 0:\n",
    "                self.is_sick = True\n",
    "            if random_number == 1:\n",
    "                self.number_of_poo = min (self.number_of_poo + 1, 4)\n",
    "\n",
    "    #Used in mainwindow - removes sickness\n",
    "    def cure(self):\n",
    "        self.is_sick = False\n",
    "\n",
    "    #The function witch decreases all the stats every second\n",
    "    #or is called when tamagotchi is sleeping\n",
    "    def second_pass(self, seconds=1):\n",
    "        \"Докато спиш всички статове падат за 8 часа, освен сънят, който се възстановява\"\n",
    "        \"As long as you sleep, all the stats fall for 8 hours, except for the sleep that is recovering\"\n",
    "        self.time += 1 \n",
    "        \n",
    "        # let's see what happens if make it a finite problem (though should really be same w discounted futures but...)\n",
    "        if self.time >= 1000:\n",
    "            self.is_dead = True\n",
    "        \n",
    "        if self.is_sleeping:\n",
    "            self.increase_to_maximum(\"energy\", 3, seconds)\n",
    "            self.decrease_to_minimum(\"happiness\", 20, seconds)\n",
    "            self.decrease_to_minimum(\"hygiene\", (20 + 2*self.number_of_poo), seconds)\n",
    "            self.decrease_to_minimum(\"food\", 20, seconds)\n",
    "            \n",
    "            # earn money while asleep\n",
    "            if self.is_playing:\n",
    "                self.money += 4*seconds # pam added\n",
    "            \n",
    "            if self.stats[\"energy\"] > 50:\n",
    "                self.is_sleeping = False\n",
    "        else:\n",
    "            \"Докато играеш, повечето статистики падат по-бързо.\"\n",
    "            \"As you play, most stats fall faster\"\n",
    "            if self.is_playing:\n",
    "                self.decrease_to_minimum(\"energy\", 3, seconds)\n",
    "                self.decrease_to_minimum(\"hygiene\", 3, seconds)\n",
    "                self.decrease_to_minimum(\"food\", 6, seconds)\n",
    "                self.increase_to_maximum(\"happiness\", 1, seconds)\n",
    "                self.money += 4*seconds # pam added\n",
    "            else:\n",
    "                self.decrease_to_minimum(\"energy\", 4, seconds)\n",
    "                self.decrease_to_minimum(\"hygiene\", 4 / (self.number_of_poo + 1), seconds)\n",
    "                self.decrease_to_minimum(\"food\", 8, seconds)\n",
    "                self.decrease_to_minimum(\"happiness\", 4, seconds)\n",
    "\n",
    "        if (self.stats[\"happiness\"] <= 50 or\n",
    "               self.stats[\"hygiene\"] <= 50):\n",
    "                self.is_sick = True\n",
    "                \n",
    "        if self.is_sick:\n",
    "            self.decrease_to_minimum(\"health\", 3, seconds)\n",
    "\n",
    "        self.constrain_stats()\n",
    "\n",
    "        self.random_event()\n",
    "\n",
    "        if (self.stats[\"food\"] == 0 or self.stats[\"health\"] == 0):\n",
    "            self.is_dead = True\n",
    "        \n",
    "        #add (?) that if energy is <=20 then goes to sleep\n",
    "        if self.stats[\"energy\"] <=20:\n",
    "            self.is_sleeping = True\n",
    "\n",
    "    #The function is called when an item is chosen and\n",
    "    #applies its statistics\n",
    "    def buy_item(self, item):\n",
    "        self.apply(item)\n",
    "        self.money -= item[\"price\"]\n",
    "        return self\n",
    "    \n",
    "    # so that tuple(tamagotchi) can be called, make tamagotchi iterable\n",
    "    def __iter__(self):\n",
    "        traits = [tuple(self.stats.items()),\n",
    "                 self.is_sleeping,\n",
    "                 self.is_dead,\n",
    "                 self.is_playing,\n",
    "                 self.is_sick,\n",
    "                 self.number_of_poo,\n",
    "                 self.money,\n",
    "                 self.time,\n",
    "                 self.in_store]\n",
    "        for i in range(len(traits)):\n",
    "            yield traits[i]\n",
    "                \n",
    "    \n",
    "    def print_tama(self):\n",
    "        print(\"Time:\",self.time,\" seconds elapsed\")\n",
    "        if self.is_dead:\n",
    "            print(\"Tama is dead!\")\n",
    "    \n",
    "        print(\"TAMA STATS: \", self.stats)\n",
    "        if self.is_sleeping:\n",
    "            print(\"Tama is asleep.\")\n",
    "        else:\n",
    "            print(\"Tama is awake.\")\n",
    "            if self.is_playing:\n",
    "                print(\"Tama is playing.\")\n",
    "            if self.is_sick:\n",
    "                print(\"Tama is sick.\")\n",
    "        print(\"Number of poo:\",self.number_of_poo)\n",
    "        print(\"Money:\",self.money)\n",
    "        if self.in_store:\n",
    "            print(\"You're in the store, so you can buy an item if you want.\")\n",
    "        else:\n",
    "            print(\"You're not in the store, so you can play, do nothing, or travel to the store.\")\n",
    "                \n",
    "        print(\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# game class:\n",
    "# defines transition probs, legal actions, reward probs, observation probs \n",
    "class Tamagotchi_Game():\n",
    "    def __init__(self):\n",
    "#         self.tamagotchi = tamagotchi\n",
    "        self.time_passing = True\n",
    "        self.observation_prob = 0.8\n",
    "    \n",
    "    # start game \n",
    "#     def start(self,state):\n",
    "#         self.time_passing = True\n",
    "#         return state\n",
    "        \n",
    "    # not used, but would be useful for a human playing the game to take breaks\n",
    "#     def pause(self):\n",
    "#         self.time_passing = False\n",
    "#         return self.tamagotchi\n",
    "        \n",
    "    # given a tuple tamagotchi \"state\" and action \"action\", what would the next tama state be?\n",
    "    # this contains the transition function for the POMDP\n",
    "    def next_state(self, tupstate, action):\n",
    "        \n",
    "        state = unpack(tupstate)   \n",
    "        \n",
    "        free_acts = ['nothing','check-happy','check-energy',\n",
    "                     'check-food','check-health','check-hygiene',\n",
    "                     'check-asleep','check-playing','check-money',\n",
    "                     'check-sick','check-instore','check-numpoo']\n",
    "        \n",
    "        if action in free_acts and not action == 'nothing':\n",
    "#             state.is_playing = False\n",
    "            state.second_pass()\n",
    "            return tuple(state) # one second passes nothing else happens\n",
    "          \n",
    "        if state.in_store:\n",
    "            state.is_playing = False\n",
    "            state.second_pass() # does this need to be state.second_pass()\n",
    "\n",
    "            if action == 'nothing': # leave the store\n",
    "                state.in_store = False\n",
    "                return tuple(state)\n",
    "            elif action == 'coffee':\n",
    "                return tuple(state.buy_item({\"stats\":\"energy\",\"price\":3,\"effect\":8})) if state.money>=3 else tuple(state)\n",
    "            elif action == 'snack':\n",
    "                return tuple(state.buy_item({\"stats\":\"food\",\"price\":3,\"effect\":8})) if state.money>=3 else tuple(state)\n",
    "            elif action == 'clean':\n",
    "                state.number_of_poo =0\n",
    "                return tuple(state.buy_item({\"stats\":\"hygiene\",\"price\":5,\"effect\":10})) if state.money>=5 else tuple(state)\n",
    "            elif action == 'medicine':\n",
    "                state.cure()\n",
    "                return tuple(state.buy_item({\"stats\":\"health\",\"price\":8,\"effect\":15})) if state.money>=8 else tuple(state)\n",
    "            else:\n",
    "                raise Exception('Invalid action while in store')\n",
    "\n",
    "        if action == 'play':\n",
    "            state.is_playing = True\n",
    "            state.second_pass()\n",
    "            # if the tama is sleeping, playing won't earn any money - tama needs to be awake\n",
    "            return tuple(state)\n",
    "\n",
    "        # \"walk\" to the store (takes one turn)\n",
    "        if action == 'store':\n",
    "            state.is_playing = False\n",
    "            state.in_store = True\n",
    "            state.second_pass()\n",
    "            return tuple(state)\n",
    "\n",
    "        if action == 'nothing':\n",
    "            state.is_playing = False\n",
    "            state.second_pass()\n",
    "            return tuple(state)\n",
    "       \n",
    "    # observation function for the POMDP\n",
    "    # if other actions provide observations, put that info in here, so this fxn looks more\n",
    "    # like next_state (e.g., if action = \"snack\" then observe hunger level)\n",
    "    def observation(self, tupletama, action):        \n",
    "        stats = dict(tupletama[0])\n",
    "        if action == 'check-happy':\n",
    "            return ['happiness', stats['happiness']]\n",
    "        elif action == 'check-energy':\n",
    "            return ['energy', stats['energy']]\n",
    "        elif action == 'check-food':\n",
    "            return ['food', stats['food']]\n",
    "        elif action == 'check-health':\n",
    "            return ['health', stats['health']]\n",
    "        elif action == 'check-hygiene':\n",
    "            return ['hygiene', stats['hygiene']]\n",
    "        elif action == 'check-asleep':\n",
    "            return [1,tupletama[1]]\n",
    "        elif action == 'check-playing':\n",
    "            return [3,tupletama[3]]\n",
    "        elif action == 'check-sick':\n",
    "            return [4,tupletama[4]]\n",
    "        elif action == 'check-money':\n",
    "            return [6,tupletama[6]]\n",
    "        elif action == 'check-instore':\n",
    "            return [8,tupletama[8]]\n",
    "        elif action == 'check-numpoo':\n",
    "            return [5,tupletama[5]]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        \n",
    "    # Take the full action and observation history, and return the full list\n",
    "    # of actions that are legal actions\n",
    "    def legal_actions(self, history): \n",
    "        # this method is important for MDPs/games where the actions might change based on the game state\n",
    "        # for instance, in checkers, if player put a piece on square A4, no other piece can move to A4\n",
    "        \n",
    "        # get object version of most recent tamagotchi state\n",
    "#         tama = self.unpack(state_history[-1])\n",
    "#         tupletama = state_history[-1] # avoid unpacking bc it takes a long time to do\n",
    "#         print(history)\n",
    "        last_act = history[-1]\n",
    "        \n",
    "        # actions you can take whenever wherever\n",
    "        free_acts = ['nothing','check-happy','check-energy',\n",
    "                     'check-food','check-health','check-hygiene',\n",
    "                     'check-asleep','check-playing','check-money',\n",
    "                     'check-sick','check-instore','check-numpoo']\n",
    "        \n",
    "        if last_act==[] or last_act=='play':\n",
    "            return ['play','store'] + free_acts\n",
    "        elif last_act in ['store','coffee','snack','clean','medicine']:\n",
    "            return ['coffee','snack','clean','medicine'] + free_acts\n",
    "        else:\n",
    "            return self.legal_actions(history[:-1])\n",
    "        \n",
    "#         if not tupletama[2]: # not dead\n",
    "#             if tupletama[8]: # in store\n",
    "#                 if tupletama[6] >= 8:\n",
    "#                     return ['coffee','snack','clean','medicine'] + free_acts\n",
    "#                 elif tupletama[6] >= 5:\n",
    "#                     return ['coffee','snack','clean'] + free_acts\n",
    "#                 elif tupletama[6] >= 3:\n",
    "#                     return ['coffee','snack'] + free_acts\n",
    "#                 else: # too poor to shop :(\n",
    "#                     return free_acts\n",
    "#             else: \n",
    "#                 return ['play','store'] + free_acts\n",
    "#         else:\n",
    "#             return []\n",
    "\n",
    "    def legal_actions_state(self,state):\n",
    "        # actions you can take whenever wherever\n",
    "        free_acts = ['nothing','check-happy','check-energy',\n",
    "                     'check-food','check-health','check-hygiene',\n",
    "                     'check-asleep','check-playing','check-money',\n",
    "                     'check-sick','check-instore','check-numpoo']\n",
    "        if state[8]: # in store\n",
    "            return ['coffee','snack','clean','medicine'] + free_acts\n",
    "        else: \n",
    "            return ['play','store'] + free_acts\n",
    "#         if not state[2]: # not dead\n",
    "#         else:\n",
    "#             return []\n",
    "    \n",
    "    # Should this be the length of state_history (how long tama alive for)? or is it trial by trial rwd?\n",
    "    def reward(self, tupletama,action):\n",
    "#         tupletama = state_history[-1]\n",
    "        \n",
    "        done = False\n",
    "        if tupletama[2]: # tama dead\n",
    "            reward = tupletama[7] + 1 # you killed the tama :'( enjoy your MONEY\n",
    "            done = True\n",
    "        else:\n",
    "            # reward is how long you kept the tama alive\n",
    "#             reward = tupletama[7] + 1 \n",
    "            reward = 0\n",
    "\n",
    "        return reward, done\n",
    "    \n",
    "    # GENERATOR MODEL OF TAMAGOTCHI GAME\n",
    "    # returns next state, observation, and reward given an action taken in given state\n",
    "    # takes tuple state\n",
    "    def G_model(self,state,action):\n",
    "        s = self.next_state(state,action)\n",
    "        obs = self.observation(state,action)\n",
    "        rwd,done = self.reward(state,action) # note that this should be more like immediate reward of state, not long-term?\n",
    "        return s, obs, rwd, done\n",
    "    \n",
    "#     # does this need to be a class method?\n",
    "#     def unpack(self,tupletama):\n",
    "#         tama = Tamagotchi()\n",
    "#         tama.stats = dict(tupletama[0])\n",
    "#         tama.is_sleeping = tupletama[1]\n",
    "#         tama.is_dead = tupletama[2]\n",
    "#         tama.is_playing = tupletama[3]\n",
    "#         tama.is_sick = tupletama[4]\n",
    "#         tama.number_of_poo = tupletama[5]\n",
    "#         tama.money = tupletama[6]\n",
    "#         tama.time = tupletama[7]\n",
    "#         tama.in_store = tupletama[8]\n",
    "#         return tama\n",
    "    \n",
    "    # Initial state distribution\n",
    "    # is this ok? or slow bc transform to tuple?\n",
    "    def sample_prior(self):\n",
    "        s = Tamagotchi()\n",
    "        return tuple(s)\n",
    "    \n",
    "    # when filtering particles, this is the rule to keep one given a real observation\n",
    "    def keep_particle(self, part, real_obs):\n",
    "        trash_prob = 0.8\n",
    "        if real_obs == []:\n",
    "            return True\n",
    "        if part != real_obs and random.random() < trash_prob:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    #     if real_obs == []:\n",
    "    #         return True\n",
    "    #     else:\n",
    "    #         if part == real_obs:\n",
    "    #             return True\n",
    "    #     return False\n",
    "\n",
    "    \n",
    "    # generate a new particle from one randomly sampled from current belief (e.g., just add a lil noise)\n",
    "    # this might need work\n",
    "    def new_particle(self, part):\n",
    "        noise = [-2,-1,0,1,2] # add some artificial noise\n",
    "        s = part\n",
    "        stats = dict(s[0])\n",
    "        for statistic, value in stats.items():\n",
    "            stats[statistic] = constrain(stats[statistic] + random.choice(noise))\n",
    "        return s\n",
    "    \n",
    "# does this need to be a class method?\n",
    "def unpack(tupletama):\n",
    "    tama = Tamagotchi()\n",
    "    tama.stats = dict(tupletama[0])\n",
    "    tama.is_sleeping = tupletama[1]\n",
    "    tama.is_dead = tupletama[2]\n",
    "    tama.is_playing = tupletama[3]\n",
    "    tama.is_sick = tupletama[4]\n",
    "    tama.number_of_poo = tupletama[5]\n",
    "    tama.money = tupletama[6]\n",
    "    tama.time = tupletama[7]\n",
    "    tama.in_store = tupletama[8]\n",
    "    return tama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SearchTree(object):\n",
    "    def __init__(self,visits=1,value=0):\n",
    "        self.visits = visits\n",
    "        self.value = value\n",
    "        self.children=[]\n",
    "        \n",
    "        \n",
    "class ActionNode(SearchTree):\n",
    "    def __init__(self,action=None,visits=1,value=0):\n",
    "        super().__init__(visits,value)\n",
    "        self.action = action\n",
    "        \n",
    "        \n",
    "class ObservationNode(SearchTree):\n",
    "    def __init__(self,observation=[],visits=1,value=0,belief=[]):\n",
    "        super().__init__(visits,value)\n",
    "        self.observation = observation\n",
    "        self.belief = belief\n",
    "        \n",
    "    def expand(self, legal_actions):\n",
    "        for a in legal_actions:\n",
    "            self.children += [ActionNode(a)]\n",
    "            \n",
    "        # upper confidence bound value for given node \"child\"\n",
    "    def ucb(self, child): #maybe use index of child not object\n",
    "#         print(\"self.visit=\",self.visit,\" len of self.children=\",len(self.children))\n",
    "        logval = math.log(self.visits) #, len(self.children))\n",
    "        div = logval / child.visits\n",
    "        return math.sqrt(div)\n",
    "    \n",
    "#     def sample_belief(self):\n",
    "#         return random.choice(self.belief)\n",
    "    \n",
    "    def next_hist(self,action,obs):\n",
    "        act_child = next((c for c in self.children if c.action==action), None)\n",
    "        assert act_child != None, \"shouldn't you be expanded already?\"\n",
    "        assert isinstance(act_child, ActionNode), \"action child should be an action node!\"\n",
    "        \n",
    "        obs_child = next((c for c in act_child.children if c.observation == obs), None) \n",
    "        if obs_child is None:\n",
    "            act_child.children += [ObservationNode(obs)]\n",
    "#             print(act_child.children[0].observation)\n",
    "            obs_child = next((c for c in act_child.children if c.observation == obs), None)     \n",
    "        return obs_child\n",
    "    \n",
    "#     def next_hist_rollout(self,action,obs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class POMCP:\n",
    "    def __init__(self, \n",
    "                 game,\n",
    "                 discount=0.8,\n",
    "                 explore=1,\n",
    "                 epsilon=1e-7,\n",
    "                 n_particles=100,\n",
    "                 reinvigoration=20, \n",
    "                 **kwargs):\n",
    "        \n",
    "#         self.context = {}\n",
    "        self.game = game\n",
    "        self.discount = discount\n",
    "        self.epsilon = epsilon\n",
    "        self.explore = explore\n",
    "        self.n_particles = n_particles\n",
    "        self.reinvigoration = reinvigoration\n",
    "        self.G = game.G_model      \n",
    "        self.tree = None\n",
    "        self.history = []\n",
    "        # list of all possible actions\n",
    "#         self.actions = kwargs.get('actions') \n",
    "        \n",
    "        seconds = kwargs.get('time',30)\n",
    "        self.calculation_time = datetime.timedelta(seconds=seconds)\n",
    "        self.maxdepth = kwargs.get('maxdepth',20)\n",
    "        self.nsims = kwargs.get('nsims',1000)\n",
    "        \n",
    "    def search(self,obs):\n",
    "        \n",
    "        self.history += [obs]\n",
    "        \n",
    "        if self.tree is None:\n",
    "            self.tree = ObservationNode(obs)                        \n",
    "#             particle = self.game.sample_prior()\n",
    "#             self.simulate(particle,self.tree,0)\n",
    "        else:\n",
    "            self.prune_tree(obs)\n",
    "            \n",
    "        for _ in range(self.nsims):\n",
    "            particle = self.draw_sample()\n",
    "            self.simulate(particle,self.tree,0)\n",
    "        \n",
    "        child = self.greedy_action_selection(self.tree,self.game.legal_actions(self.history)) # will again need to handle legal actions differently for real\n",
    "        self.tree = child # move forward to child action node (will move to obs node when real obs occurs)\n",
    "        self.history += [child.action]\n",
    "        \n",
    "        return child.action\n",
    "    \n",
    "    def simulate(self,state,tree,depth):\n",
    "        if depth >= self.maxdepth:\n",
    "            return 0\n",
    "        \n",
    "#         legal = self.game.legal_actions(state,tree,depth)\n",
    "#         legal = self.game.legal_actions(self.history) # would want it to be more elegant/complicated for real\n",
    "        legal = self.game.legal_actions_state(state)\n",
    "    \n",
    "        if len(tree.children) == 0:\n",
    "            tree.expand(legal)\n",
    "            return self.rollout(state,depth)\n",
    "        \n",
    "        if len(legal)==1:\n",
    "            action = legal[0]\n",
    "            child = tree.children[0]\n",
    "        else:\n",
    "            child = self.ucb_action_selection(tree,legal)\n",
    "            action = child.action\n",
    "            \n",
    "        next_state, next_obs, r, done = self.G(state,action)\n",
    "        if done:\n",
    "            return r\n",
    "        next_tree = tree.next_hist(action,next_obs)\n",
    "        reward = r + self.discount * self.simulate(next_state,next_tree,depth+1)\n",
    "        \n",
    "        tree.belief += [state] \n",
    "        tree.visits += 1\n",
    "        \n",
    "        child.visits += 1\n",
    "        child.value += (reward - child.value)/child.visits\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def rollout(self,state,depth):\n",
    "        if depth >= self.maxdepth:\n",
    "            return 0\n",
    "        \n",
    "#         legal = self.game.legal_actions(self.history)\n",
    "        legal = self.game.legal_actions_state(state)\n",
    "        a = random.choice(legal)\n",
    "        \n",
    "        next_state, next_obs, r, done = self.G(state,a)\n",
    "#         next_tree = tree.next_hist(a,next_obs)\n",
    "        \n",
    "        if done:\n",
    "            return r\n",
    "        \n",
    "        return r + self.discount * self.rollout(next_state,depth+1)\n",
    "        \n",
    "    ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
    "    ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "    ## ## ## ## ## FIX THIS !! ## ## ## ## ## ## ## \n",
    "    ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##\n",
    "    ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
    "    def prune_tree(self,obs):\n",
    "        #current tree is an action node. find child node with observation obs\n",
    "        obs_child = next((c for c in self.tree.children if c.observation == obs), None) \n",
    "        self.tree = obs_child\n",
    "        return\n",
    "        \n",
    "    def greedy_action_selection(self,tree,legal):\n",
    "        children = [child for child in tree.children if child.action in legal] #filter(lambda child: child.action in legal_actions, tree.children)\n",
    "        child_vals = np.array([child.value for child in children])\n",
    "        favechildren = np.argwhere(child_vals == np.amax(child_vals))\n",
    "        child = children[random.choice(favechildren.flatten().tolist())]\n",
    "        return child\n",
    "        \n",
    "    def ucb_action_selection(self,tree,legal):\n",
    "        children = [child for child in tree.children if child.action in legal] #filter(lambda child: child.action in legal_actions, tree.children)\n",
    "        child_vals = np.array([child.value + self.explore * tree.ucb(child) for child in children])\n",
    "        favechildren = np.argwhere(child_vals == np.amax(child_vals))\n",
    "        child = children[random.choice(favechildren.flatten().tolist())]\n",
    "        return child\n",
    "    \n",
    "    def draw_sample(self):\n",
    "        \n",
    "        if not isinstance(self.tree, ObservationNode):\n",
    "            pdb.set_trace()\n",
    "#         assert isinstance(self.tree, ObservationNode), \"why you not an obs node ?!?!\"\n",
    "        if self.tree.belief == []:\n",
    "            return self.game.sample_prior()\n",
    "        else:\n",
    "            return random.choice(self.tree.belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tuple(Tamagotchi())\n",
    "game = Tamagotchi_Game()\n",
    "agent = POMCP(game, 0.9, maxdepth=20, nsims=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL STATE: \n",
      "((('food', 100), ('happiness', 100), ('hygiene', 100), ('health', 100), ('energy', 100)), False, False, False, False, 0, 0, 0, False)\n",
      "Taking action: check-energy\n",
      "observed  ['energy', 98.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the tree runs simulations to choose the next action using the choose_move() method\n",
    "\n",
    "print(\"INITIAL STATE: \")\n",
    "print(s) # initial tiger problem state\n",
    "\n",
    "obs = []\n",
    "\n",
    "action = agent.search(obs)\n",
    "print(\"Taking action:\", action)\n",
    "obs = game.observation(state,action)\n",
    "if obs!=[]:\n",
    "    print(\"observed \",obs)\n",
    "state = game.next_state(s,action)\n",
    "game.reward(s,action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsims =  100\n",
      "INITIAL STATE: \n",
      "((('food', 100), ('happiness', 100), ('hygiene', 100), ('health', 100), ('energy', 100)), False, False, False, False, 0, 0, 0, False)\n",
      "Action 1: True state is ((('food', 100), ('happiness', 100), ('hygiene', 100), ('health', 100), ('energy', 100)), False, False, False, False, 0, 0, 0, False)\n",
      "Taking action check-numpoo.\n",
      "observed  [5, 0]\n",
      "Reward so far:  0\n",
      "Action 2: True state is ((('food', 98.0), ('happiness', 98.0), ('hygiene', 98.0), ('health', 100), ('energy', 98.0)), False, False, False, False, 0, 0, 1, False)\n",
      "Taking action check-sick.\n",
      "observed  [4, False]\n",
      "Reward so far:  0\n",
      "Action 3: True state is ((('food', 96.0), ('happiness', 96.0), ('hygiene', 96.0), ('health', 100), ('energy', 96.0)), False, False, False, False, 0, 0, 2, False)\n",
      "Taking action check-sick.\n",
      "observed  [4, False]\n",
      "Reward so far:  0\n",
      "Action 4: True state is ((('food', 94.0), ('happiness', 94.0), ('hygiene', 94.0), ('health', 100), ('energy', 94.0)), False, False, False, False, 0, 0, 3, False)\n",
      "Taking action check-instore.\n",
      "observed  [8, False]\n",
      "Reward so far:  0\n",
      "Action 5: True state is ((('food', 92.0), ('happiness', 92.0), ('hygiene', 92.0), ('health', 100), ('energy', 92.0)), False, False, False, False, 0, 0, 4, False)\n",
      "Taking action store.\n",
      "Reward so far:  0\n",
      "Action 6: True state is ((('food', 90.0), ('happiness', 90.0), ('hygiene', 90.0), ('health', 100), ('energy', 90.0)), False, False, False, False, 0, 0, 5, True)\n",
      "Taking action nothing.\n",
      "Reward so far:  0\n",
      "Action 7: True state is ((('food', 88.0), ('happiness', 88.0), ('hygiene', 88.0), ('health', 100), ('energy', 88.0)), False, False, False, False, 0, 0, 6, False)\n",
      "Taking action check-playing.\n",
      "observed  [3, False]\n",
      "Reward so far:  0\n",
      "Action 8: True state is ((('food', 86.0), ('happiness', 86.0), ('hygiene', 86.0), ('health', 100), ('energy', 86.0)), False, False, False, False, 0, 0, 7, False)\n",
      "Taking action check-energy.\n",
      "observed  ['energy', 86.0]\n",
      "Reward so far:  0\n",
      "Action 9: True state is ((('food', 84.0), ('happiness', 84.0), ('hygiene', 84.0), ('health', 100), ('energy', 84.0)), False, False, False, False, 0, 0, 8, False)\n",
      "Taking action check-money.\n",
      "observed  [6, 0]\n",
      "Reward so far:  0\n",
      "Action 10: True state is ((('food', 82.0), ('happiness', 82.0), ('hygiene', 82.0), ('health', 100), ('energy', 82.0)), False, False, False, False, 0, 0, 9, False)\n",
      "Taking action nothing.\n",
      "Reward so far:  0\n",
      "Action 11: True state is ((('food', 80.0), ('happiness', 80.0), ('hygiene', 80.0), ('health', 100), ('energy', 80.0)), False, False, False, False, 0, 0, 10, False)\n",
      "Taking action check-health.\n",
      "observed  ['health', 100]\n",
      "Reward so far:  0\n",
      "Action 12: True state is ((('food', 78.0), ('happiness', 78.0), ('hygiene', 78.0), ('health', 100), ('energy', 78.0)), False, False, False, False, 0, 0, 11, False)\n",
      "Taking action check-numpoo.\n",
      "observed  [5, 0]\n",
      "Reward so far:  0\n",
      "Action 13: True state is ((('food', 76.0), ('happiness', 76.0), ('hygiene', 76.0), ('health', 100), ('energy', 76.0)), False, False, False, False, 0, 0, 12, False)\n",
      "Taking action check-food.\n",
      "observed  ['food', 76.0]\n",
      "Reward so far:  0\n",
      "> <ipython-input-38-9868e1226800>(124)draw_sample()\n",
      "-> if self.tree.belief == []:\n",
      "(Pdb) self.tree\n",
      "(Pdb) self\n",
      "<__main__.POMCP object at 0x133014160>\n",
      "(Pdb) self.tree == None\n",
      "True\n",
      "(Pdb) c\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'belief'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-094402f91e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# play for a certain amount of time (better rule?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0maction_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Action %i: True state is %s'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-9868e1226800>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mparticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-9868e1226800>\u001b[0m in \u001b[0;36mdraw_sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m#         assert isinstance(self.tree, ObservationNode), \"why you not an obs node ?!?!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelief\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'belief'"
     ]
    }
   ],
   "source": [
    "# now let's compare the performance of different nsims n\n",
    "\n",
    "storeobservations = []\n",
    "storeactions = []\n",
    "storerewards = []\n",
    "ns = [100, 500, 1000, 5000, 10000]\n",
    "c = 20\n",
    "\n",
    "for n in ns:\n",
    "    print(\"nsims = \", n)\n",
    "    # Initialize the tiger\n",
    "    s = tuple(Tamagotchi())\n",
    "    game = Tamagotchi_Game()\n",
    "\n",
    "    print(\"INITIAL STATE: \")\n",
    "    print(s) # initial tiger state\n",
    "\n",
    "    agent = POMCP(game, 0.9, c, maxdepth=20, nsims=n)\n",
    "\n",
    "    action_seq = []\n",
    "    obs_seq = []\n",
    "    state = s\n",
    "    obs = []\n",
    "    R = 0\n",
    "\n",
    "\n",
    "    while len(action_seq) < 20: # play for a certain amount of time (better rule?)\n",
    "\n",
    "        action = agent.search(obs)\n",
    "        action_seq.append(action)\n",
    "        print('Action %i: True state is %s'% (len(action_seq), state))\n",
    "        print(\"Taking action %s.\"% action)\n",
    "\n",
    "        obs = game.observation(state,action)\n",
    "        obs_seq.append(obs)\n",
    "        \n",
    "        if obs!=[]:\n",
    "            print(\"observed \",obs)\n",
    "\n",
    "        r,_= game.reward(state,action)\n",
    "        R = R + r\n",
    "        print(\"Reward so far: \",R)    \n",
    "\n",
    "        state = game.next_state(state,action)\n",
    "\n",
    "    print(\"game over!\")\n",
    "    storeobservations.append([obs_seq])\n",
    "    storeactions.append([action_seq])\n",
    "    storerewards.append(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
